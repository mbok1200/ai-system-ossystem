import os, re, hashlib, logging, PyPDF2, ebooklib, chardet
from typing import List, Dict, Optional
from pathlib import Path
import pandas as pd
from docx import Document
from ebooklib import epub
from bs4 import BeautifulSoup
from sentence_transformers import SentenceTransformer

from openai import OpenAI
from pinecone import Pinecone, ServerlessSpec
from dotenv import load_dotenv

load_dotenv(".env")

class DocumentLoader:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É–≤–∞—á –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –≤ Pinecone –≤–µ–∫—Ç–æ—Ä–Ω—É –±–∞–∑—É"""
    
    def __init__(self, pinecone_index_name: str, auto_create_index: bool = True, dimension: int = 1024):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è DocumentLoader
        
        Args:
            pinecone_index_name: –ù–∞–∑–≤–∞ —ñ–Ω–¥–µ–∫—Å—É Pinecone
            auto_create_index: –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ —ñ–Ω–¥–µ–∫—Å —è–∫—â–æ –Ω–µ —ñ—Å–Ω—É—î
            dimension: –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä—ñ–≤ (768 –¥–ª—è multilingual-e5-base)
        """
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # Pinecone
        self.pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
        self.index_name = pinecone_index_name
        self.dimension = dimension
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —ñ–Ω–¥–µ–∫—Å (—Å—Ç–≤–æ—Ä—é—î–º–æ —è–∫—â–æ –Ω–µ —ñ—Å–Ω—É—î)
        self.index = self._init_pinecone_index(auto_create_index)
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∑–Ω–∞—á–∞—î–º–æ –º–æ–¥–µ–ª—å embedding –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ —ñ–Ω–¥–µ–∫—Å—É
        self._detect_embedding_model()
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
        self.chunk_size = 1000  # –†–æ–∑–º—ñ—Ä —á–∞–Ω–∫—ñ–≤
        self.chunk_overlap = 200  # –ü–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è –º—ñ–∂ —á–∞–Ω–∫–∞–º–∏
        
        # –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏
        self.supported_formats = {
            '.pdf': self._load_pdf,
            '.docx': self._load_docx,
            '.doc': self._load_docx,
            '.xlsx': self._load_excel,
            '.xls': self._load_excel,
            '.csv': self._load_csv,
            '.epub': self._load_epub,
            '.txt': self._load_text,
            '.md': self._load_text,
            '.py': self._load_text,
            '.json': self._load_text,
            '.jsonl': self._load_text
        }    
    def _init_pinecone_index(self, auto_create: bool = True):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Pinecone —ñ–Ω–¥–µ–∫—Å—É –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è–º"""
        try:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —ñ—Å–Ω—É—î —ñ–Ω–¥–µ–∫—Å
            existing_indexes = [idx.name for idx in self.pc.list_indexes()]
            
            if self.index_name in existing_indexes:
                return self.pc.Index(self.index_name)
            
            # –Ø–∫—â–æ —ñ–Ω–¥–µ–∫—Å –Ω–µ —ñ—Å–Ω—É—î —ñ auto_create=True
            if auto_create:                
                # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Å–ø–µ—Ü–∏—Ñ—ñ–∫–∞—Ü—ñ—é –¥–ª—è –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ–≥–æ –ø–ª–∞–Ω—É
                spec = ServerlessSpec(
                    cloud='aws',  # –∞–±–æ 'gcp'
                    region='us-east-1'  # —Ä–µ–≥—ñ–æ–Ω –¥–ª—è –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ–≥–æ –ø–ª–∞–Ω—É
                )
                
                # –°—Ç–≤–æ—Ä—é—î–º–æ —ñ–Ω–¥–µ–∫—Å
                self.pc.create_index(
                    name=self.index_name,
                    dimension=self.dimension,  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–µ—Ä–µ–¥–∞–Ω—É —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å
                    metric='cosine',  # –ú–µ—Ç—Ä–∏–∫–∞ –ø–æ–¥—ñ–±–Ω–æ—Å—Ç—ñ
                    spec=spec
                )
                
                # –ß–µ–∫–∞—î–º–æ –ø–æ–∫–∏ —ñ–Ω–¥–µ–∫—Å –±—É–¥–µ –≥–æ—Ç–æ–≤–∏–π
                import time
                max_wait_time = 60  # –º–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥
                wait_time = 0
                
                while wait_time < max_wait_time:
                    try:
                        index = self.pc.Index(self.index_name)
                        return index
                    except Exception as e:
                        time.sleep(5)
                        wait_time += 5
                
                # –Ø–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –¥–æ—á–µ–∫–∞—Ç–∏—Å—è
                raise Exception(f"Timeout waiting for index {self.index_name}")
                
            else:
                raise Exception(f"–Ü–Ω–¥–µ–∫—Å '{self.index_name}' –Ω–µ —ñ—Å–Ω—É—î —ñ auto_create=False")
                
        except Exception as e:
            raise e
    
    def create_index_if_not_exists(self, dimension: int = 1024, metric: str = 'cosine') -> Dict:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—É —è–∫—â–æ –≤—ñ–Ω –Ω–µ —ñ—Å–Ω—É—î (–ø—É–±–ª—ñ—á–Ω–∏–π –º–µ—Ç–æ–¥)"""
        try:
            existing_indexes = [idx.name for idx in self.pc.list_indexes()]
            
            if self.index_name in existing_indexes:
                return {
                    'success': True,
                    'message': f'–Ü–Ω–¥–µ–∫—Å {self.index_name} –≤–∂–µ —ñ—Å–Ω—É—î',
                    'already_exists': True
                }
            
            # –°–ø–µ—Ü–∏—Ñ—ñ–∫–∞—Ü—ñ—è –¥–ª—è serverless
            spec = ServerlessSpec(
                cloud='aws',
                region='us-east-1'
            )
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —ñ–Ω–¥–µ–∫—Å
            self.pc.create_index(
                name=self.index_name,
                dimension=dimension,
                metric=metric,
                spec=spec
            )
            
            # –û–Ω–æ–≤–ª—é—î–º–æ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è
            self.index = self.pc.Index(self.index_name)
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –≥–æ—Ç–æ–≤–Ω—ñ—Å—Ç—å
            import time
            for i in range(12):  # 60 —Å–µ–∫—É–Ω–¥ –º–∞–∫—Å–∏–º—É–º
                try:
                    stats = self.index.describe_index_stats()
                    return {
                        'success': True,
                        'message': f'–Ü–Ω–¥–µ–∫—Å {self.index_name} —Å—Ç–≤–æ—Ä–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ',
                        'dimension': stats.dimension,
                        'created': True
                    }
                except Exception as wait_error:
                    if i < 11:
                        time.sleep(5)
                    else:
                        return {
                            'success': False,
                            'error': f'Timeout waiting for index readiness: {str(wait_error)}'
                        }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def delete_index(self) -> Dict:
        """–û–ë–ï–†–ï–ñ–ù–û: –í–∏–¥–∞–ª–µ–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—É"""
        try:
            self.pc.delete_index(self.index_name)            
            return {
                'success': True,
                'message': f'–Ü–Ω–¥–µ–∫—Å {self.index_name} –≤–∏–¥–∞–ª–µ–Ω–æ'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def list_all_indexes(self) -> Dict:
        """–°–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤"""
        try:
            indexes = self.pc.list_indexes()
            index_info = []
            
            for idx in indexes:
                try:
                    # –û—Ç—Ä–∏–º—É—î–º–æ –¥–µ—Ç–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —ñ–Ω–¥–µ–∫—Å
                    index_obj = self.pc.Index(idx.name)
                    stats = index_obj.describe_index_stats()
                    
                    info = {
                        'name': idx.name,
                        'dimension': stats.dimension,
                        'total_vectors': stats.total_vector_count,
                        'namespaces': list(stats.namespaces.keys()) if stats.namespaces else [],
                        'status': 'ready'
                    }
                except Exception as index_error:
                    info = {
                        'name': idx.name,
                        'status': 'error',
                        'error': str(index_error)
                    }
                
                index_info.append(info)
            
            return {
                'success': True,
                'indexes': index_info,
                'total_count': len(index_info)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_index_info(self) -> Dict:
        """–î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø–æ—Ç–æ—á–Ω–∏–π —ñ–Ω–¥–µ–∫—Å"""
        try:
            stats = self.index.describe_index_stats()
            
            # –î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ —ñ–Ω–¥–µ–∫—Å
            index_description = None
            try:
                # –°–ø—Ä–æ–±—É—î–º–æ –æ—Ç—Ä–∏–º–∞—Ç–∏ –æ–ø–∏—Å —ñ–Ω–¥–µ–∫—Å—É
                indexes = self.pc.list_indexes()
                for idx in indexes:
                    if idx.name == self.index_name:
                        index_description = {
                            'name': idx.name,
                            'metric': getattr(idx, 'metric', 'unknown'),
                            'spec': str(getattr(idx, 'spec', 'unknown'))
                        }
                        break
            except Exception as desc_error:
                index_description = '–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –æ–ø–∏—Å —ñ–Ω–¥–µ–∫—Å—É'
            
            return {
                'success': True,
                'index_name': self.index_name,
                'dimension': stats.dimension,
                'total_vectors': stats.total_vector_count,
                'namespaces': dict(stats.namespaces) if stats.namespaces else {},
                'index_description': index_description,
                'embedding_model': getattr(self, 'embedding_model', 'unknown'),
                'ready': True
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'index_name': self.index_name,
                'ready': False
            }

    def check_index_status(self) -> Dict:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞–Ω—É —ñ–Ω–¥–µ–∫—Å—É"""
        try:
            stats = self.index.describe_index_stats()
            
            result = {
                'exists': True,
                'total_vectors': stats.total_vector_count,
                'dimension': stats.dimension,
                'namespaces': dict(stats.namespaces) if stats.namespaces else {},
                'is_empty': stats.total_vector_count == 0
            }
            return result
            
        except Exception as e:
            return {
                'exists': False,
                'error': str(e),
                'is_empty': True
            }
    
    def load_directory(self, directory_path: str, recursive: bool = True) -> Dict:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö —Ñ–∞–π–ª—ñ–≤ –∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó"""
        directory = Path(directory_path)
        if not directory.exists() or not directory.is_dir():
            return {'success': False, 'error': f'–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –Ω–µ —ñ—Å–Ω—É—î: {directory}'}
        
        print(f"üìÅ –°–∫–∞–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é: {directory}")
        print(f"üîç –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ: {'–¢–∞–∫' if recursive else '–ù—ñ'}")
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–∞–π–ª–∏
        files_to_process = []

        try:
            if recursive:
                print(f"üîÑ –†–µ–∫—É—Ä—Å–∏–≤–Ω–∏–π –ø–æ—à—É–∫ —Ñ–∞–π–ª—ñ–≤...")
                for ext in self.supported_formats.keys():
                    found_files = list(directory.rglob(f"*{ext}"))
                    print(f"   {ext}: –∑–Ω–∞–π–¥–µ–Ω–æ {len(found_files)} —Ñ–∞–π–ª—ñ–≤")
                    files_to_process.extend(found_files)
            else:
                print(f"üìÇ –ü–æ—à—É–∫ —Ç—ñ–ª—å–∫–∏ –≤ –ø–æ—Ç–æ—á–Ω—ñ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó...")
                for ext in self.supported_formats.keys():
                    found_files = list(directory.glob(f"*{ext}"))
                    print(f"   {ext}: –∑–Ω–∞–π–¥–µ–Ω–æ {len(found_files)} —Ñ–∞–π–ª—ñ–≤")
                    files_to_process.extend(found_files)
                    
        except Exception as e:
            return {'success': False, 'error': f'–ü–æ–º–∏–ª–∫–∞ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è: {str(e)}'}
    
        print(f"üìä –í—Å—å–æ–≥–æ –∑–Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª—ñ–≤: {len(files_to_process)}")
        
        if not files_to_process:
            return {'success': False, 'error': '–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤'}
        
        # –ü–æ–∫–∞–∑—É—î–º–æ —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª—ñ–≤
        print(f"üìã –§–∞–π–ª–∏ –¥–ª—è –æ–±—Ä–æ–±–∫–∏:")
        for i, file_path in enumerate(files_to_process, 1):
            print(f"   {i}. {file_path.name} ({file_path.suffix})")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ñ–∞–π–ª–∏
        results = []
        successful = 0
        
        # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–æ–±–ª—è—î–º–æ —Ñ–∞–π–ª–∏
        for i, file_path in enumerate(files_to_process, 1):
            try:
                print(f"\nüìÑ –û–±—Ä–æ–±–ª—è—é —Ñ–∞–π–ª {i}/{len(files_to_process)}: {file_path.name}")
                
                # file_path –≤–∂–µ —î Path –æ–±'—î–∫—Ç–æ–º, –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ —Å—Ç—Ä–æ–∫—É
                result = self.load_file(str(file_path))
                results.append(result)
                
                if result['success']:
                    successful += 1
                    print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ: {result.get('vectors_uploaded', 0)} –≤–µ–∫—Ç–æ—Ä—ñ–≤")
                else:
                    print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                error_result = {'success': False, 'error': str(e), 'file': str(file_path)}
                results.append(error_result)
                print(f"‚ùå –í–∏–Ω—è—Ç–æ–∫ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ {file_path.name}: {e}")
                continue
            
            # –î–æ–¥–∞—î–º–æ –Ω–µ–≤–µ–ª–∏–∫—É –ø–∞—É–∑—É –º—ñ–∂ —Ñ–∞–π–ª–∞–º–∏
            import time
            time.sleep(0.1)
        
        print(f"\nüìà –ü—ñ–¥—Å—É–º–æ–∫:")
        print(f"‚úÖ –£—Å–ø—ñ—à–Ω–∏—Ö: {successful}")
        print(f"‚ùå –ü–æ–º–∏–ª–æ–∫: {len(files_to_process) - successful}")
        print(f"üìÅ –í—Å—å–æ–≥–æ —Ñ–∞–π–ª—ñ–≤: {len(files_to_process)}")
        
        return {
            'success': successful > 0,
            'total_files': len(files_to_process),
            'successful': successful,
            'failed': len(files_to_process) - successful,
            'results': results
        }
    
    def load_file(self, file_path: str, source_name: Optional[str] = None) -> Dict:
        print(f"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {Path(file_path)} –≤–µ–∫—Ç–æ—Ä—ñ–≤")
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª—É"""
        file_path = Path(file_path)
        if not file_path.exists():
            return {'success': False, 'error': f'–§–∞–π–ª –Ω–µ —ñ—Å–Ω—É—î: {file_path}'}
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ç–∏–ø —Ñ–∞–π–ª—É
        file_ext = file_path.suffix.lower()
        if file_ext not in self.supported_formats:
            return {
                'success': False, 
                'error': f'–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {file_ext}. –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ: {list(self.supported_formats.keys())}'
            }
        
        try:            
            # –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç –∑ —Ñ–∞–π–ª—É
            loader_func = self.supported_formats[file_ext]
            text_content = loader_func(file_path)
            
            if not text_content:
                return {'success': False, 'error': '–§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –≤–∏—Ç—è–≥—Ç–∏ —Ç–µ–∫—Å—Ç'}
            
            # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —á–∞–Ω–∫–∏
            chunks = self._split_text(text_content)
            
            if not chunks:
                return {'success': False, 'error': '–ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ —á–∞–Ω–∫–∏'}
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤ Pinecone
            source = source_name or file_path.name
            
            result = self._upload_chunks(chunks, source, str(file_path))
            
            if result.get('error'):
                return {
                    'success': False, 
                    'error': result['error'],
                    'partial_upload': result.get('uploaded', 0)
                }
            
            return {
                'success': True,
                'file': str(file_path),
                'source': source,
                'chunks_created': len(chunks),
                'vectors_uploaded': result['uploaded'],
                'text_length': len(text_content)
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _load_pdf(self, file_path: Path) -> str:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è PDF"""
        text = ""
        try:
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                for page_num, page in enumerate(reader.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n--- –°—Ç–æ—Ä—ñ–Ω–∫–∞ {page_num + 1} ---\n{page_text}\n"
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è PDF {file_path}: {e}")
        
        return text.strip()
    
    def _load_docx(self, file_path: Path) -> str:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è DOCX"""
        try:
            doc = Document(file_path)
            text = ""
            
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text += paragraph.text + "\n"
            
            # –¢–∞–∫–æ–∂ –≤–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç –∑ —Ç–∞–±–ª–∏—Ü—å
            for table in doc.tables:
                for row in table.rows:
                    row_text = " | ".join([cell.text.strip() for cell in row.cells])
                    if row_text.strip():
                        text += row_text + "\n"
            
            return text.strip()
            
        except Exception as e:
            return ""
    
    def _load_excel(self, file_path: Path) -> str:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Excel"""
        try:
            # –ß–∏—Ç–∞—î–º–æ –≤—Å—ñ –ª–∏—Å—Ç–∏
            dfs = pd.read_excel(file_path, sheet_name=None)
            text = ""
            
            for sheet_name, df in dfs.items():
                text += f"\n--- –õ–∏—Å—Ç: {sheet_name} ---\n"
                text += df.to_string(index=False) + "\n"
            
            return text.strip()
            
        except Exception as e:
            return ""
    
    def _load_csv(self, file_path: Path) -> str:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è CSV"""
        try:
            df = pd.read_csv(file_path)
            return df.to_string(index=False)
        except Exception as e:
            return ""
    
    def _load_epub(self, file_path: Path) -> str:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è EPUB"""
        try:
            book = epub.read_epub(file_path)
            text = ""
            
            for item in book.get_items():
                if item.get_type() == ebooklib.ITEM_DOCUMENT:
                    soup = BeautifulSoup(item.get_content(), 'html.parser')
                    chapter_text = soup.get_text()
                    if chapter_text.strip():
                        text += chapter_text + "\n\n"
            
            return text.strip()
            
        except Exception as e:
            return ""
    
    def _load_text(self, file_path: Path) -> str:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö —Ñ–∞–π–ª—ñ–≤"""
        try:
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫–æ–¥—É–≤–∞–Ω–Ω—è
            with open(file_path, 'rb') as file:
                raw_data = file.read()
                encoding = chardet.detect(raw_data)['encoding'] or 'utf-8'
            
            # –ß–∏—Ç–∞—î–º–æ —Ñ–∞–π–ª
            with open(file_path, 'r', encoding=encoding) as file:
                return file.read()
                
        except Exception as e:
            return ""
    
    def _split_text(self, text: str) -> List[str]:
        """–†–æ–∑–±–∏—Ç—Ç—è —Ç–µ–∫—Å—Ç—É –Ω–∞ —á–∞–Ω–∫–∏"""
        chunks = []
        
        # –ü—Ä–æ—Å—Ç–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–æ–∑–±–∏—Ç—Ç—è –ø–æ —Ä–µ—á–µ–Ω–Ω—è—Ö
        sentences = text.split('.')
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –Ω–µ –ø–µ—Ä–µ–≤–∏—â—É—î–º–æ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å —á–∞–Ω–∫–∞
            if len(current_chunk + sentence) < self.chunk_size:
                current_chunk += sentence + ". "
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ". "
        
        # –î–æ–¥–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π —á–∞–Ω–∫
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def _upload_chunks(self, chunks: List[str], source: str, file_path: str) -> Dict:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —á–∞–Ω–∫—ñ–≤ –≤ Pinecone –∑ –¥–µ—Ç–∞–ª—å–Ω–∏–º –ª–æ–≥—É–≤–∞–Ω–Ω—è–º"""
        uploaded = 0
        errors = []
        
        try:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –ø–µ—Ä–µ–¥ –ø–æ—á–∞—Ç–∫–æ–º
            stats = self.index.describe_index_stats()
            initial_count = stats.total_vector_count            
            vectors_to_upsert = []
            
            for i, chunk in enumerate(chunks):
                if not chunk.strip():
                    continue
                
                try:
                    # –ì–µ–Ω–µ—Ä—É—î–º–æ embedding
                    embedding = self._get_embedding(chunk)
                    # –°—Ç–≤–æ—Ä—é—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID (ASCII —Ç—ñ–ª—å–∫–∏)
                    chunk_id = self._generate_chunk_id(source, i, chunk)
                    # –û—á–∏—â—É—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ –≤—ñ–¥ –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤
                    clean_source = self._clean_text_for_metadata(source)
                    clean_file_path = self._clean_text_for_metadata(file_path)
                    clean_chunk = chunk[:1000]  # –û–±–º–µ–∂—É—î–º–æ —Ä–æ–∑–º—ñ—Ä –º–µ—Ç–∞–¥–∞–Ω–∏—Ö
                    
                    # –ú–µ—Ç–∞–¥–∞–Ω—ñ
                    metadata = {
                        'text': clean_chunk,
                        'source': clean_source,
                        'file_path': clean_file_path,
                        'chunk_index': i,
                        'title': f"{clean_source} - —á–∞—Å—Ç–∏–Ω–∞ {i+1}"
                    }
                    
                    vector = {
                        'id': chunk_id,
                        'values': embedding,
                        'metadata': metadata
                    }
                    
                    vectors_to_upsert.append(vector)
                    
                    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –±–∞—Ç—á–∞–º–∏ –ø–æ 100
                    if len(vectors_to_upsert) >= 100:
                        # –î–ï–¢–ê–õ–¨–ù–ï –õ–û–ì–£–í–ê–ù–ù–Ø UPSERT
                        try:
                            upsert_response = self.index.upsert(vectors=vectors_to_upsert)
                            uploaded += len(vectors_to_upsert)
                            vectors_to_upsert = []
                            
                            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –¥—ñ–π—Å–Ω–æ –¥–æ–¥–∞–ª–∏—Å—è –≤–µ–∫—Ç–æ—Ä–∏
                            import time
                            time.sleep(1)  # –ù–µ–≤–µ–ª–∏–∫–∞ –ø–∞—É–∑–∞ –¥–ª—è —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó
                            
                        except Exception as upsert_error:
                            errors.append(f"Upsert error: {str(upsert_error)}")
                            vectors_to_upsert = []  # –û—á–∏—â—É—î–º–æ –±–∞—Ç—á
                            continue
                
                except Exception as chunk_error:
                    error_msg = f"–ß–∞–Ω–∫ {i}: {str(chunk_error)}"
                    errors.append(error_msg)
                    continue
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏
            if vectors_to_upsert:
                try:
                    uploaded += len(vectors_to_upsert)
                except Exception as final_upsert_error:
                    errors.append(f"Final upsert error: {str(final_upsert_error)}")
            result = {'uploaded': uploaded}
            if errors:
                result['errors'] = errors
                result['error_count'] = len(errors)
            
            return result
            
        except Exception as e:
            return {
                'uploaded': uploaded, 
                'error': str(e),
                'errors': errors
            }
    
    def _clean_text_for_metadata(self, text: str) -> str:
        """–û—á–∏—â–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –¥–ª—è –±–µ–∑–ø–µ—á–Ω–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –º–µ—Ç–∞–¥–∞–Ω–∏—Ö"""
        import re
        
        # –ó–∞–º—ñ–Ω—é—î–º–æ –ø—Ä–æ–±–ª–µ–º–Ω—ñ —Å–∏–º–≤–æ–ª–∏
        clean_text = re.sub(r'[^\w\s\-\.\(\)]+', '_', text)
        
        # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É (Pinecone –º–∞—î –ª—ñ–º—ñ—Ç–∏ –Ω–∞ –º–µ—Ç–∞–¥–∞–Ω—ñ)
        if len(clean_text) > 200:
            clean_text = clean_text[:200] + "..."
        
        return clean_text.strip()
    
    def _detect_embedding_model(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ embedding –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ —ñ–Ω–¥–µ–∫—Å—É"""
        try:
            stats = self.index.describe_index_stats()
            dimension = stats.dimension
            
            if dimension == 1536:
                self.embedding_model = "text-embedding-ada-002"
            elif dimension == 768:
                self.embedding_model = "text-embedding-3-small"
            elif dimension == 3072:
                self.embedding_model = "text-embedding-3-large"
            else:
                # Fallback –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É –º–æ–¥–µ–ª—å
                self.embedding_model = "local"
                
        except Exception as e:
            self.embedding_model = "text-embedding-3-small"
    
    def _get_embedding(self, text: str) -> List[float]:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è embedding –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –≤–∏–±–æ—Ä–æ–º –º–æ–¥–µ–ª—ñ"""
        try:
            # –°–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å —ñ–Ω–¥–µ–∫—Å—É
            stats = self.index.describe_index_stats()
            expected_dim = stats.dimension
            
            if self.embedding_model == "local" or expected_dim == 1024:
                return self._get_local_embedding(text)
            else:
                response = self.openai_client.embeddings.create(
                    input=text,
                    model=self.embedding_model
                )
                embedding = response.data[0].embedding
                
                # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ
                if len(embedding) != expected_dim:
                    return self._get_local_embedding(text)
                
                return embedding
                
        except Exception as e:
            return self._get_local_embedding(text)
    
    def _get_local_embedding(self, text: str) -> List[float]:
        """–õ–æ–∫–∞–ª—å–Ω–∏–π embedding –¥–ª—è –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏—Ö —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç–µ–π"""
        try:
            
            # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –º–æ–¥–µ–ª—å —è–∫—â–æ —â–µ –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞
            if not hasattr(self, '_local_model'):
                # –ú–æ–¥–µ–ª—å –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏ –∑ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—é 768
                self._local_model = SentenceTransformer('intfloat/multilingual-e5-base')
            
            embedding = self._local_model.encode(text).tolist()
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å
            stats = self.index.describe_index_stats()
            expected_dim = stats.dimension
            
            if len(embedding) != expected_dim:
                # –û–±—Ä—ñ–∑–∞—î–º–æ –∞–±–æ –¥–æ–ø–æ–≤–Ω—é—î–º–æ –¥–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ—ó —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ
                if len(embedding) > expected_dim:
                    embedding = embedding[:expected_dim]
                else:
                    embedding.extend([0.0] * (expected_dim - len(embedding)))
            return embedding
            
        except ImportError:
            raise Exception("–õ–æ–∫–∞–ª—å–Ω—ñ embedding –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ. –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å: pip install sentence-transformers")
        except Exception as e:
            raise e
    
    def _generate_chunk_id(self, source: str, chunk_index: int, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ ID –¥–ª—è —á–∞–Ω–∫–∞ (—Ç—ñ–ª—å–∫–∏ ASCII)"""
        
        # –û—á–∏—â—É—î–º–æ source –≤—ñ–¥ –Ω–µ-ASCII —Å–∏–º–≤–æ–ª—ñ–≤
        clean_source = re.sub(r'[^\x00-\x7F]+', '_', source)  # –ó–∞–º—ñ–Ω—é—î–º–æ –∫–∏—Ä–∏–ª–∏—Ü—é –Ω–∞ _
        clean_source = re.sub(r'[^a-zA-Z0-9_\-]', '_', clean_source)  # –¢—ñ–ª—å–∫–∏ –±—É–∫–≤–∏, —Ü–∏—Ñ—Ä–∏, _ —Ç–∞ -
        clean_source = clean_source.strip('_')[:50]  # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É
        
        # –•–µ—à —Ç–µ–∫—Å—Ç—É –¥–ª—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ—Å—Ç—ñ
        text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()[:8]
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ ASCII ID
        chunk_id = f"{clean_source}_{chunk_index}_{text_hash}"
        
        # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ - –∑–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ ASCII
        chunk_id = ''.join(char for char in chunk_id if ord(char) < 128)
        
        # –Ø–∫—â–æ ID —Å—Ç–∞–≤ –ø–æ—Ä–æ–∂–Ω—ñ–º, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback
        if not chunk_id:
            chunk_id = f"doc_{chunk_index}_{text_hash}"
        
        return chunk_id
    
    def clear_index(self) -> Dict:
        """–û–ë–ï–†–ï–ñ–ù–û: –û—á–∏—â–µ–Ω–Ω—è –≤—Å—å–æ–≥–æ —ñ–Ω–¥–µ–∫—Å—É"""
        try:
            # –û—Ç—Ä–∏–º—É—î–º–æ –≤—Å—ñ ID
            stats = self.index.describe_index_stats()
            if stats.total_vector_count == 0:
                return {'success': True, 'message': '–Ü–Ω–¥–µ–∫—Å –≤–∂–µ –ø–æ—Ä–æ–∂–Ω—ñ–π'}
            
            # –í–∏–¥–∞–ª—è—î–º–æ –≤—Å–µ (—Ü–µ –Ω–µ–±–µ–∑–ø–µ—á–Ω–∞ –æ–ø–µ—Ä–∞—Ü—ñ—è!)
            self.index.delete(delete_all=True)
            return {
                'success': True, 
                'message': f'–í–∏–¥–∞–ª–µ–Ω–æ {stats.total_vector_count} –≤–µ–∫—Ç–æ—Ä—ñ–≤'
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}